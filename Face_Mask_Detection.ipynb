{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanishkashetty/Face-Mask-Detection/blob/main/Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bt3aiax_EAAb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HtwdSvwGFFa9"
      },
      "outputs": [],
      "source": [
        "train_dir = r'/content/drive/MyDrive/Final_Assignment_Face Mask Dataset/Train'\n",
        "validation_dir = r'/content/drive/MyDrive/Final_Assignment_Face Mask Dataset/Validation'\n",
        "test_dir =r'/content/drive/MyDrive/Final_Assignment_Face Mask Dataset/Test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LdMJIM8vFYi8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aYw8gBuHFnhw"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYbBKiRtGZlr",
        "outputId": "5c423273-f4fc-4851-f822-7b941da12ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3410 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=20,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bT3pgqm0GcTO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IOHVEDPdGha0"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(128, 128, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mm99h9SDHJnU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZqNMJVHRzh",
        "outputId": "9452978b-bb36-4d95-ebdb-f6f7b5697da4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "170/170 [==============================] - 374s 2s/step - loss: 0.0083 - acc: 0.9997 - val_loss: 11.1802 - val_acc: 0.5000\n",
            "Epoch 2/20\n",
            "170/170 [==============================] - 113s 665ms/step - loss: 1.1059e-08 - acc: 1.0000 - val_loss: 14.3423 - val_acc: 0.5000\n",
            "Epoch 3/20\n",
            "170/170 [==============================] - 110s 649ms/step - loss: 9.7972e-10 - acc: 1.0000 - val_loss: 15.1825 - val_acc: 0.5000\n",
            "Epoch 4/20\n",
            "170/170 [==============================] - 110s 648ms/step - loss: 4.9117e-10 - acc: 1.0000 - val_loss: 15.5945 - val_acc: 0.5000\n",
            "Epoch 5/20\n",
            "170/170 [==============================] - 110s 647ms/step - loss: 3.3195e-10 - acc: 1.0000 - val_loss: 15.8869 - val_acc: 0.5000\n",
            "Epoch 6/20\n",
            "170/170 [==============================] - 110s 649ms/step - loss: 2.5202e-10 - acc: 1.0000 - val_loss: 16.0299 - val_acc: 0.5000\n",
            "Epoch 7/20\n",
            "170/170 [==============================] - 112s 658ms/step - loss: 2.1601e-10 - acc: 1.0000 - val_loss: 16.1748 - val_acc: 0.5000\n",
            "Epoch 8/20\n",
            "170/170 [==============================] - 111s 650ms/step - loss: 1.8654e-10 - acc: 1.0000 - val_loss: 16.2988 - val_acc: 0.5000\n",
            "Epoch 9/20\n",
            "170/170 [==============================] - 111s 650ms/step - loss: 1.6139e-10 - acc: 1.0000 - val_loss: 16.3985 - val_acc: 0.5000\n",
            "Epoch 10/20\n",
            "170/170 [==============================] - 111s 651ms/step - loss: 1.4863e-10 - acc: 1.0000 - val_loss: 16.4989 - val_acc: 0.5000\n",
            "Epoch 11/20\n",
            "170/170 [==============================] - 111s 650ms/step - loss: 1.3214e-10 - acc: 1.0000 - val_loss: 16.5763 - val_acc: 0.5000\n",
            "Epoch 12/20\n",
            "170/170 [==============================] - 111s 652ms/step - loss: 1.2195e-10 - acc: 1.0000 - val_loss: 16.6543 - val_acc: 0.5000\n",
            "Epoch 13/20\n",
            "170/170 [==============================] - 111s 650ms/step - loss: 1.1184e-10 - acc: 1.0000 - val_loss: 16.7327 - val_acc: 0.5000\n",
            "Epoch 14/20\n",
            "170/170 [==============================] - 111s 651ms/step - loss: 1.0105e-10 - acc: 1.0000 - val_loss: 16.8117 - val_acc: 0.5000\n",
            "Epoch 15/20\n",
            "170/170 [==============================] - 111s 652ms/step - loss: 9.3481e-11 - acc: 1.0000 - val_loss: 16.8912 - val_acc: 0.5000\n",
            "Epoch 16/20\n",
            "170/170 [==============================] - 111s 651ms/step - loss: 8.4755e-11 - acc: 1.0000 - val_loss: 16.9456 - val_acc: 0.5000\n",
            "Epoch 17/20\n",
            "170/170 [==============================] - 111s 651ms/step - loss: 8.0605e-11 - acc: 1.0000 - val_loss: 17.0004 - val_acc: 0.5000\n",
            "Epoch 18/20\n",
            "170/170 [==============================] - 111s 651ms/step - loss: 7.7017e-11 - acc: 1.0000 - val_loss: 17.0553 - val_acc: 0.5000\n",
            "Epoch 19/20\n",
            "170/170 [==============================] - 111s 653ms/step - loss: 4.4232e-11 - acc: 1.0000 - val_loss: 17.0836 - val_acc: 0.5000\n",
            "Epoch 20/20\n",
            "170/170 [==============================] - 111s 653ms/step - loss: 6.9805e-11 - acc: 1.0000 - val_loss: 17.1389 - val_acc: 0.5000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=170,\n",
        "      epochs=20,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CbdZo0vgHfOm"
      },
      "outputs": [],
      "source": [
        "model.save(\"model_cnn_project_P1.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "anyhz5O2Hgrk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6cYDKI0oHkCj"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGsThTGxH_Lc",
        "outputId": "38f1533a-b222-4a36-b5b3-a5378aee97f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3410 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(128, 128),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h6fr-HfxIInY"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(128, 128, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_dTbfRU7IMIs"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W5_hYtSIPrI",
        "outputId": "cc41e5ce-ac4c-4596-e221-fd15e2201b08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "106/106 [==============================] - 123s 1s/step - loss: 0.0124 - acc: 0.9970 - val_loss: 9.9887 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 2.3383e-07 - acc: 1.0000 - val_loss: 15.5979 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 2.1816e-09 - acc: 1.0000 - val_loss: 16.5564 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 2.3348e-09 - acc: 1.0000 - val_loss: 17.6327 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 4.9917e-10 - acc: 1.0000 - val_loss: 17.9252 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 2.9777e-10 - acc: 1.0000 - val_loss: 18.0918 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 3.4040e-10 - acc: 1.0000 - val_loss: 18.3082 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 1.2067e-10 - acc: 1.0000 - val_loss: 18.3983 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 9.8842e-11 - acc: 1.0000 - val_loss: 18.4448 - val_acc: 0.5000\n",
            "Epoch 10/10\n",
            "106/106 [==============================] - 119s 1s/step - loss: 1.6527e-10 - acc: 1.0000 - val_loss: 18.5644 - val_acc: 0.5000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=106,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ISUi4onIUvg",
        "outputId": "7a37c2ee-4e26-4f95-f270-11a23ae475df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "80150528/80134624 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG19\n",
        "\n",
        "conv_base = VGG19(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(128, 128, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qogWPveeIYG-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H1pC9OVhIbHf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OcVtAc5IIfaK"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"CNN_Final_Project_Model-{epoch:02d}.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1I9QGqhwlHr",
        "outputId": "2c18561d-d4b9-4006-dee9-3e5be0f42f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "106/106 [==============================] - 2931s 27s/step - loss: 0.0020 - acc: 1.0000 - val_loss: 8.9670 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "106/106 [==============================] - 2820s 27s/step - loss: 1.0554e-08 - acc: 1.0000 - val_loss: 10.9378 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "106/106 [==============================] - 2807s 27s/step - loss: 8.2689e-10 - acc: 1.0000 - val_loss: 11.1067 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "106/106 [==============================] - 2819s 27s/step - loss: 7.1193e-10 - acc: 1.0000 - val_loss: 11.3217 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "106/106 [==============================] - 2835s 27s/step - loss: 4.4818e-10 - acc: 1.0000 - val_loss: 11.3887 - val_acc: 0.5000\n",
            "Epoch 6/10\n",
            "106/106 [==============================] - 2840s 27s/step - loss: 3.8011e-10 - acc: 1.0000 - val_loss: 11.3887 - val_acc: 0.5000\n",
            "Epoch 7/10\n",
            "106/106 [==============================] - 2840s 27s/step - loss: 3.9414e-10 - acc: 1.0000 - val_loss: 11.4104 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "106/106 [==============================] - 2826s 27s/step - loss: 3.7845e-10 - acc: 1.0000 - val_loss: 11.4567 - val_acc: 0.5000\n",
            "Epoch 9/10\n",
            " 86/106 [=======================>......] - ETA: 8:22 - loss: 3.4854e-10 - acc: 1.0000"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=106,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=25,\n",
        "      callbacks=[checkpoint_cb])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Face Mask_Detection.ipynb",
      "toc_visible": true,
      "provenance": [],
      "mount_file_id": "1nJ-XR9AlH0PwbhOkrVbddvjEEuFA00qh",
      "authorship_tag": "ABX9TyPmSEgNSQr1y/bb9hKr/vBv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}